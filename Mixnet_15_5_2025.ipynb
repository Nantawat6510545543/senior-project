{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6lsjPKNf-tp"
      },
      "source": [
        "# Click \"cancel\" if prompted to restart session for installation setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFocrA45ASfE"
      },
      "source": [
        "# Mixnet Installation Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggTRSbohiTY5"
      },
      "source": [
        "## Virtual Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HTDByGZyszJ",
        "outputId": "561f6e7f-5cdd-4d61-814c-3c482d176f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.8 is already the newest version (3.8.20-1+jammy1).\n",
            "python3.8-distutils is already the newest version (3.8.20-1+jammy1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Install Python 3.8\n",
        "!sudo apt-get install python3.8 python3.8-distutils\n",
        "\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgK6WLCs-hUS"
      },
      "outputs": [],
      "source": [
        "# Switch to Python 3.8\n",
        "!sudo update-alternatives  --set python3 /usr/bin/python3.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud1gQXVl00VK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d6a0da-7f65-4120-95c4-3ae4de126152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/python\n",
            "Python 3.8.20\n"
          ]
        }
      ],
      "source": [
        "# Check Python Path and Version\n",
        "!which python\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOfnD-lZ_O4t",
        "outputId": "38275425-7f2e-471a-da36-1659360e0c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-pip' instead of 'pip'\n",
            "python3-pip is already the newest version (22.0.2+dfsg-1ubuntu0.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Install pip (if not installed)\n",
        "!sudo apt install pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYgwjLyIKT4D",
        "outputId": "0ee10ce4-022d-4ae5-963a-0498862f9062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.8-venv is already the newest version (3.8.20-1+jammy1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Install venv\n",
        "!sudo apt-get install python3.8-venv\n",
        "\n",
        "# Create venv\n",
        "!python3.8 -m venv mixnet_env\n",
        "\n",
        "# Activage venv\n",
        "!source mixnet_env/bin/activate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nI74SyFi-tK"
      },
      "source": [
        "## Install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy4Cb2ryOGX4",
        "outputId": "23665e13-d4c6-40cb-9a9b-5d1d46add420"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.7.0 in /usr/local/lib/python3.8/dist-packages (2.7.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/lib/python3/dist-packages (from tensorflow==2.7.0) (0.37.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (4.13.2)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.70.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow==2.7.0) (1.16.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (18.1.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (5.29.4)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.17.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (2.0.7)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (2.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (1.24.4)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (0.34.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (2.14.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.7.0) (3.5.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.40.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.7.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (59.6.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.0.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.9.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (5.5.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.6->tensorflow==2.7.0) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/lib/python3/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.0) (4.6.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.26.20)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.6->tensorflow==2.7.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.6->tensorflow==2.7.0) (3.2.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tensorflow-gpu==2.7.0 in /usr/local/lib/python3.8/dist-packages (2.7.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow-gpu==2.7.0) (1.16.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (3.5.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (2.14.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (4.13.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (18.1.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (1.17.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (1.70.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (0.34.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (2.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/lib/python3/dist-packages (from tensorflow-gpu==2.7.0) (0.37.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (5.29.4)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (2.2.2)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gpu==2.7.0) (1.24.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (1.0.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (3.0.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (59.6.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (2.32.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (2.40.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0) (0.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0) (0.4.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0) (5.5.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.6->tensorflow-gpu==2.7.0) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/lib/python3/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu==2.7.0) (4.6.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0) (2025.4.26)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0) (1.26.20)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0) (3.4.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.6->tensorflow-gpu==2.7.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.6->tensorflow-gpu==2.7.0) (3.2.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tensorflow-addons==0.16.1 in /usr/local/lib/python3.8/dist-packages (0.16.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons==0.16.1) (4.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.8/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.13.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/lib/python3/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.6.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: h5py==3.5.0 in /usr/local/lib/python3.8/dist-packages (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.5 in /usr/local/lib/python3.8/dist-packages (from h5py==3.5.0) (1.24.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: mne in /usr/local/lib/python3.8/dist-packages (1.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: scipy>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from mne) (1.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: matplotlib>=3.5.0 in /usr/local/lib/python3.8/dist-packages (from mne) (3.7.5)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.8/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.8/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from mne) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.8/dist-packages (from mne) (1.24.4)\n",
            "Requirement already satisfied: importlib-resources>=5.10.2 in /usr/local/lib/python3.8/dist-packages (from mne) (6.4.5)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=5.10.2->mne) (3.20.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.5.0->mne) (0.12.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.5.0->mne) (10.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.5.0->mne) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.5.0->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.5.0->mne) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.5.0->mne) (1.4.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.5.0->mne) (4.57.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->mne) (2.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5.0->mne) (1.16.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.20)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.4.26)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: moabb in /usr/local/lib/python3.8/dist-packages (1.0.0)\n",
            "Requirement already satisfied: mne<2.0,>=1.4 in /usr/local/lib/python3.8/dist-packages (from moabb) (1.6.1)\n",
            "Requirement already satisfied: pyriemann<0.6,>=0.5 in /usr/local/lib/python3.8/dist-packages (from moabb) (0.5)\n",
            "Requirement already satisfied: pytest<8.0.0,>=7.4.0 in /usr/local/lib/python3.8/dist-packages (from moabb) (7.4.4)\n",
            "Requirement already satisfied: memory-profiler<0.62.0,>=0.61.0 in /usr/local/lib/python3.8/dist-packages (from moabb) (0.61.0)\n",
            "Requirement already satisfied: edflib-python<2.0.0,>=1.0.6 in /usr/local/lib/python3.8/dist-packages (from moabb) (1.0.8)\n",
            "Requirement already satisfied: mne-bids<0.14,>=0.13 in /usr/local/lib/python3.8/dist-packages (from moabb) (0.13)\n",
            "Requirement already satisfied: pooch<2.0.0,>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from moabb) (1.8.2)\n",
            "Requirement already satisfied: PyYAML<7.0,>=6.0 in /usr/local/lib/python3.8/dist-packages (from moabb) (6.0.2)\n",
            "Requirement already satisfied: h5py<=3.8.0 in /usr/local/lib/python3.8/dist-packages (from moabb) (3.5.0)\n",
            "Requirement already satisfied: coverage<8.0.0,>=7.0.1 in /usr/local/lib/python3.8/dist-packages (from moabb) (7.6.1)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.6.2 in /usr/local/lib/python3.8/dist-packages (from moabb) (3.7.5)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.26.15 in /usr/local/lib/python3.8/dist-packages (from moabb) (1.26.20)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.5.2 in /usr/local/lib/python3.8/dist-packages (from moabb) (1.5.3)\n",
            "Requirement already satisfied: seaborn<0.13.0,>=0.12.1 in /usr/local/lib/python3.8/dist-packages (from moabb) (0.12.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.3 in /usr/local/lib/python3.8/dist-packages (from moabb) (1.10.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.22 in /usr/local/lib/python3.8/dist-packages (from moabb) (1.24.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.8/dist-packages (from moabb) (2.32.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /usr/local/lib/python3.8/dist-packages (from moabb) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from moabb) (1.3.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (10.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (2.4.7)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (6.4.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (0.12.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (2.9.0.post0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4.0.0,>=3.6.2->moabb) (4.57.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from memory-profiler<0.62.0,>=0.61.0->moabb) (7.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from mne<2.0,>=1.4->moabb) (3.1.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from mne<2.0,>=1.4->moabb) (5.2.1)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.8/dist-packages (from mne<2.0,>=1.4->moabb) (0.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0.0,>=1.5.2->moabb) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.8/dist-packages (from pooch<2.0.0,>=1.6.0->moabb) (4.3.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from pyriemann<0.6,>=0.5->moabb) (1.4.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.8/dist-packages (from pytest<8.0.0,>=7.4.0->moabb) (1.3.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.8/dist-packages (from pytest<8.0.0,>=7.4.0->moabb) (1.5.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from pytest<8.0.0,>=7.4.0->moabb) (2.2.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.8/dist-packages (from pytest<8.0.0,>=7.4.0->moabb) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (3.4.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (2025.4.26)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.28.1->moabb) (3.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<2.0.0,>=1.2.0->moabb) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from exceptiongroup>=1.0.0rc8->pytest<8.0.0,>=7.4.0->moabb) (4.13.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=3.2.0->matplotlib<4.0.0,>=3.6.2->moabb) (3.20.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.6.2->moabb) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->mne<2.0,>=1.4->moabb) (2.1.5)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install tensorflow==2.7.0\n",
        "!pip install tensorflow-gpu==2.7.0\n",
        "!pip install tensorflow-addons==0.16.1\n",
        "!pip install scikit-learn>=1.2.2\n",
        "!pip install wget>=3.2\n",
        "!pip install h5py==3.5.0\n",
        "!pip install pandas>=2.0\n",
        "\n",
        "!pip install mne\n",
        "!pip install moabb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvzK-cIcVUbZ",
        "outputId": "e3d99a7b-13e7-43a0-fd37-a1f8fb4b9a57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.7.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.8/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, protobuf, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wheel, wrapt\n",
            "Required-by: \n",
            "Name: tensorflow-gpu\n",
            "Version: 2.7.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.8/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, protobuf, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wheel, wrapt\n",
            "Required-by: \n",
            "Name: tensorflow-addons\n",
            "Version: 0.16.1\n",
            "Summary: TensorFlow Addons.\n",
            "Home-page: UNKNOWN\n",
            "Author: Google Inc.\n",
            "Author-email: opensource@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.8/dist-packages\n",
            "Requires: typeguard\n",
            "Required-by: mixnet-bci\n",
            "Name: mne\n",
            "Version: 1.6.1\n",
            "Summary: MNE-Python project for MEG and EEG data analysis.\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Alexandre Gramfort <alexandre.gramfort@inria.fr>\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.8/dist-packages\n",
            "Requires: decorator, importlib-resources, jinja2, lazy-loader, matplotlib, numpy, packaging, pooch, scipy, tqdm\n",
            "Required-by: mne-bids, moabb\n",
            "Name: moabb\n",
            "Version: 1.0.0\n",
            "Summary: Mother of All BCI Benchmarks\n",
            "Home-page: https://github.com/NeuroTechX/moabb\n",
            "Author: Alexandre Barachant\n",
            "Author-email: \n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.8/dist-packages\n",
            "Requires: coverage, edflib-python, h5py, matplotlib, memory-profiler, mne, mne-bids, numpy, pandas, pooch, pyriemann, pytest, PyYAML, requests, scikit-learn, scipy, seaborn, tqdm, urllib3\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "# Check Install\n",
        "!pip show tensorflow\n",
        "!pip show tensorflow-gpu\n",
        "!pip show tensorflow-addons\n",
        "\n",
        "!pip show mne\n",
        "!pip show moabb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKEYR8Dn-nR_",
        "outputId": "80cde47e-45a9-4820-981d-1d6e7de68b2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mixnet-bci in /usr/local/lib/python3.8/dist-packages (1.0.0)\n",
            "Requirement already satisfied: tensorflow-addons==0.16.1 in /usr/local/lib/python3.8/dist-packages (from mixnet-bci) (0.16.1)\n",
            "Requirement already satisfied: wget>=3.2 in /usr/local/lib/python3.8/dist-packages (from mixnet-bci) (3.2)\n",
            "Requirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.8/dist-packages (from mixnet-bci) (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from mixnet-bci) (1.5.3)\n",
            "Requirement already satisfied: ray>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from mixnet-bci) (2.10.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons==0.16.1->mixnet-bci) (4.4.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.8/dist-packages (from ray>=1.11.0->mixnet-bci) (5.29.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from ray>=1.11.0->mixnet-bci) (25.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ray>=1.11.0->mixnet-bci) (1.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from ray>=1.11.0->mixnet-bci) (3.16.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from ray>=1.11.0->mixnet-bci) (8.1.8)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.8/dist-packages (from ray>=1.11.0->mixnet-bci) (1.3.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.8/dist-packages (from ray>=1.11.0->mixnet-bci) (4.23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from ray>=1.11.0->mixnet-bci) (2.32.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from ray>=1.11.0->mixnet-bci) (6.0.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.8/dist-packages (from ray>=1.11.0->mixnet-bci) (1.5.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.2.2->mixnet-bci) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.2.2->mixnet-bci) (3.5.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.2.2->mixnet-bci) (1.24.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.2.2->mixnet-bci) (1.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->mixnet-bci) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->mixnet-bci) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->mixnet-bci) (1.16.0)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/lib/python3/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1->mixnet-bci) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.8/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1->mixnet-bci) (4.13.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray>=1.11.0->mixnet-bci) (25.3.0)\n",
            "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray>=1.11.0->mixnet-bci) (1.3.10)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray>=1.11.0->mixnet-bci) (0.20.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray>=1.11.0->mixnet-bci) (2023.12.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray>=1.11.0->mixnet-bci) (6.4.5)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.8/dist-packages (from jsonschema->ray>=1.11.0->mixnet-bci) (0.35.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->ray>=1.11.0->mixnet-bci) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->ray>=1.11.0->mixnet-bci) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->ray>=1.11.0->mixnet-bci) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->ray>=1.11.0->mixnet-bci) (1.26.20)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray>=1.11.0->mixnet-bci) (3.20.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mName: mixnet-bci\n",
            "Version: 1.0.0\n",
            "Summary: MixNet: Joining Force of Classical and Modern Approaches toward The Comprehensive Pipeline in Motor Imagery EEG Classification\n",
            "Home-page: https://github.com/Max-Phairot-A/MixNet\n",
            "Author: Phairot Autthasan\n",
            "Author-email: phairot.a_s17@vistec.ac.th\n",
            "License: Apache Software License\n",
            "Location: /usr/local/lib/python3.8/dist-packages\n",
            "Requires: pandas, ray, scikit-learn, tensorflow-addons, wget\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "# Install Mixnet\n",
        "!pip install mixnet-bci\n",
        "!pip show mixnet-bci"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDGzkN3pFpuD"
      },
      "source": [
        "# Mixnet preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Cbi2L1vjKLg"
      },
      "outputs": [],
      "source": [
        "# Append Python to Path\n",
        "import sys\n",
        "sys.path.append(\"/usr/local/lib/python3.8/dist-packages/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable Eagar Execution\n",
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "3VaGieGa4f8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZRokJW1Gr89"
      },
      "outputs": [],
      "source": [
        "# Quickfix Import Issue: Manual Patch AbstractRNNCell\n",
        "import tensorflow\n",
        "from tensorflow.python.keras.layers.recurrent import AbstractRNNCell\n",
        "tensorflow.keras.layers.AbstractRNNCell = AbstractRNNCell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCri-UamyUTS",
        "outputId": "c91bfb5b-4465-4884-b5c4-42c4f4dcfbd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '__version__',\n",
              " 'callbacks',\n",
              " 'gradients',\n",
              " 'loss',\n",
              " 'models',\n",
              " 'preprocessing',\n",
              " 'trainer',\n",
              " 'utils']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# If mixnet doesn't import run Manual Patch AbstractRNNCell (the cell above) again, then run this cell\n",
        "import mixnet\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "dir(mixnet)      # Check Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fJ8tt2Gfkc-1"
      },
      "outputs": [],
      "source": [
        "# Manual for now, link is down\n",
        "# download datasets from this link, then add the 18 .mat files inside datasets/BCIC2a/raw/ folder:\n",
        "# https://www.kaggle.com/datasets/reader443/bci-competition-iv-dataset-2a-in-mat-format\n",
        "import os\n",
        "\n",
        "save_path = \"datasets/BCIC2a/raw\"\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "# dataset_name = 'BCIC2a'\n",
        "# mixnet.utils.load_raw(dataset_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO7vtLjF0gDm"
      },
      "source": [
        "# IMPORTANT: WAIT FOR FILE TO FINISH DOWNLOAD BEFORE PREPROCESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fqu5RLAbltPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c1b7245-72b6-4b77-bcad-5f87b9664b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of CSP components used is:  2 with using  2  classes data and preparing on the dataset:  BCIC2a\n",
            "chosen_channel: FC3 --- Index_is: 0\n",
            "chosen_channel: FC1 --- Index_is: 1\n",
            "chosen_channel: FCz --- Index_is: 2\n",
            "chosen_channel: FC2 --- Index_is: 3\n",
            "chosen_channel: FC4 --- Index_is: 4\n",
            "chosen_channel: C5 --- Index_is: 5\n",
            "chosen_channel: C3 --- Index_is: 6\n",
            "chosen_channel: C1 --- Index_is: 7\n",
            "chosen_channel: Cz --- Index_is: 8\n",
            "chosen_channel: C2 --- Index_is: 9\n",
            "chosen_channel: C4 --- Index_is: 10\n",
            "chosen_channel: C6 --- Index_is: 11\n",
            "chosen_channel: CP3 --- Index_is: 12\n",
            "chosen_channel: CP1 --- Index_is: 13\n",
            "chosen_channel: CPz --- Index_is: 14\n",
            "chosen_channel: CP2 --- Index_is: 15\n",
            "chosen_channel: CP4 --- Index_is: 16\n",
            "chosen_channel: P1 --- Index_is: 17\n",
            "chosen_channel: Pz --- Index_is: 18\n",
            "chosen_channel: P2 --- Index_is: 19\n",
            "Verify dimension training (144, 20, 400) and testing (144, 20, 400)\n",
            "Verify dimension training (144, 20, 400) and testing (144, 20, 400)\n",
            "Verify dimension training (144, 20, 400) and testing (144, 20, 400)\n",
            "Verify dimension training (144, 20, 400) and testing (144, 20, 400)\n",
            "Verify dimension training (144, 20, 400) and testing (144, 20, 400)\n",
            "Verify dimension training (144, 20, 400) and testing (144, 20, 400)\n",
            "Verify dimension training (144, 20, 400) and testing (144, 20, 400)\n",
            "Verify dimension training (144, 20, 400) and testing (144, 20, 400)\n",
            "Verify dimension training (144, 20, 400) and testing (144, 20, 400)\n",
            "FOLD: 1 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 1 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 1 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 1 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 1 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 116 VALIDATION: 28\n",
            "Check dimension of training data (116, 18, 400), val data (28, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 1 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 2 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 2 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 2 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 2 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 116 VALIDATION: 28\n",
            "Check dimension of training data (116, 18, 400), val data (28, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 2 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 3 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 3 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 3 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 3 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 116 VALIDATION: 28\n",
            "Check dimension of training data (116, 18, 400), val data (28, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 3 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 4 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 4 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 4 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 4 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 116 VALIDATION: 28\n",
            "Check dimension of training data (116, 18, 400), val data (28, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 4 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 5 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 5 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 5 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 5 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 116 VALIDATION: 28\n",
            "Check dimension of training data (116, 18, 400), val data (28, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 5 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 6 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 6 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 6 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 6 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 116 VALIDATION: 28\n",
            "Check dimension of training data (116, 18, 400), val data (28, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 6 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 7 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 7 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 7 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 7 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 116 VALIDATION: 28\n",
            "Check dimension of training data (116, 18, 400), val data (28, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 7 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 8 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 8 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 8 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 8 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 116 VALIDATION: 28\n",
            "Check dimension of training data (116, 18, 400), val data (28, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 8 from fold 5 is DONE!!!\n",
            "FOLD: 1 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 9 from fold 1 is DONE!!!\n",
            "FOLD: 2 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 9 from fold 2 is DONE!!!\n",
            "FOLD: 3 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 9 from fold 3 is DONE!!!\n",
            "FOLD: 4 TRAIN: 115 VALIDATION: 29\n",
            "Check dimension of training data (115, 18, 400), val data (29, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 9 from fold 4 is DONE!!!\n",
            "FOLD: 5 TRAIN: 116 VALIDATION: 28\n",
            "Check dimension of training data (116, 18, 400), val data (28, 18, 400) and testing data (144, 18, 400)\n",
            "save DONE\n",
            "The preprocessing of subject 9 from fold 5 is DONE!!!\n"
          ]
        }
      ],
      "source": [
        "import mixnet.preprocessing as prep\n",
        "from mixnet.preprocessing.config import CONSTANT\n",
        "\n",
        "k_folds = 5\n",
        "pick_smp_freq = 100\n",
        "bands = [[4, 8], [8, 12], [12, 16],\n",
        "            [16, 20], [20, 24], [24, 28],\n",
        "            [28, 32], [32, 36], [36, 40]]\n",
        "order = 5\n",
        "save_path = 'datasets'\n",
        "num_class = 2\n",
        "\n",
        "prep.BCIC2a.spectral_spatial_signals.subject_dependent_setting(k_folds=k_folds,\n",
        "                                                  pick_smp_freq=pick_smp_freq,\n",
        "                                                  n_components=2, # 2 is the optimal number of CSP components\n",
        "                                                  bands=bands,\n",
        "                                                  order=order,\n",
        "                                                  save_path=save_path,\n",
        "                                                  num_class=num_class,\n",
        "                                                  sel_chs=CONSTANT['BCIC2a']['sel_chs'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yy_69Ki50XMa"
      },
      "outputs": [],
      "source": [
        "# Might take at least 10 minutes\n",
        "# prep.BCIC2a.spectral_spatial_signals.subject_independent_setting(k_folds=k_folds,\n",
        "#                                             pick_smp_freq=pick_smp_freq,\n",
        "#                                             n_components=4, # 4 is the optimal number of CSP components\n",
        "#                                             bands=bands,\n",
        "#                                             order=order,\n",
        "#                                             save_path=save_path,\n",
        "#                                             num_class=num_class,\n",
        "#                                             sel_chs=CONSTANT['BCIC2a']['sel_chs'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rvWll1Jrqb0"
      },
      "source": [
        "# Setup Mixnet Model Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hK7sO3qMm0i5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import importlib.util\n",
        "\n",
        "from mixnet.utils import write_log, DataLoader\n",
        "\n",
        "# Define arguments manually (instead of argparse)\n",
        "class Args:\n",
        "    model_name = 'MixNet'\n",
        "    dataset = 'BCIC2a'\n",
        "    train_type = 'subject_dependent'\n",
        "    data_type = 'spectral_spatial_signals'\n",
        "    num_class = 2\n",
        "    latent_dim = None\n",
        "    loss_weights = None\n",
        "    adaptive_gradient = True\n",
        "    policy = 'HistoricalTangentSlope'\n",
        "    log_dir = 'logs'\n",
        "    subjects = None  # or None for all subjects\n",
        "    GPU = '0'\n",
        "    margin = 1.0\n",
        "    n_component = 2\n",
        "    warmup = 7\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COdmVhK4oezx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c004f2f-96c6-4272-83ef-a17e9499ca46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-15 12:41:18--  https://raw.githubusercontent.com/Max-Phairot-A/MixNet/main/experiments/configs/MixNet.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4427 (4.3K) [text/plain]\n",
            "Saving to: configs/MixNet.py\n",
            "\n",
            "configs/MixNet.py   100%[===================>]   4.32K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-15 12:41:18 (44.0 MB/s) - configs/MixNet.py saved [4427/4427]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Manual Load Config\n",
        "import os\n",
        "\n",
        "# Create the configs directory if it doesn't exist\n",
        "os.makedirs(\"configs\", exist_ok=True)\n",
        "\n",
        "# Download the file from the raw GitHub URL\n",
        "!wget -O configs/MixNet.py https://raw.githubusercontent.com/Max-Phairot-A/MixNet/main/experiments/configs/MixNet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2okcvYs7nV6F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ab3eb12-97dc-4144-b2f6-603f499c6013"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... loading config params from: configs/MixNet.py\n",
            "Experiment config loaded.\n"
          ]
        }
      ],
      "source": [
        "# Load model config\n",
        "def get_params(model_name='MyTest', **kwargs):\n",
        "    path = os.path.join('configs', model_name + '.py')  # assumes configs is in root\n",
        "    print('... loading config params from:', path)\n",
        "    spec = importlib.util.spec_from_file_location('configs.' + model_name, path)\n",
        "    Module = importlib.util.module_from_spec(spec)\n",
        "    spec.loader.exec_module(Module)\n",
        "    return Module.get_params(**kwargs)\n",
        "\n",
        "# Setup experiment config\n",
        "exp_setup = {\n",
        "    'dataset': args.dataset,\n",
        "    'train_type': args.train_type,\n",
        "    'data_type': args.data_type,\n",
        "    'num_class': args.num_class,\n",
        "    'margin': args.margin,\n",
        "    'n_component': args.n_component,\n",
        "    'warmup': args.warmup,\n",
        "    'latent_dim': args.latent_dim,\n",
        "    'loss_weights': args.loss_weights,\n",
        "    'adaptive_gradient': args.adaptive_gradient,\n",
        "    'policy': args.policy,\n",
        "    'log_dir': args.log_dir\n",
        "}\n",
        "\n",
        "config = get_params(args.model_name, **exp_setup)\n",
        "print(\"Experiment config loaded.\")\n",
        "\n",
        "# Ensure log directory exists\n",
        "os.makedirs(config.log_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmc28Zf7Lrr9"
      },
      "source": [
        "# Monkey Patching For Building Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f35ozx6bEacB"
      },
      "outputs": [],
      "source": [
        "# 1. Patch ModelCheckpoint first (it's called before Trainer.__init__)\n",
        "_original_ModelCheckpoint = tf.keras.callbacks.ModelCheckpoint\n",
        "\n",
        "def patched_ModelCheckpoint(*args, **kwargs):\n",
        "    if 'save_weight_only' in kwargs:\n",
        "        kwargs['save_weights_only'] = kwargs.pop('save_weight_only')\n",
        "    if kwargs.get('save_weights_only', False):\n",
        "        filepath = kwargs.get('filepath', '')\n",
        "        if not filepath.endswith('.weights.h5'):\n",
        "            filepath = filepath.replace('_weights.h5', '.weights.h5')\n",
        "            kwargs['filepath'] = filepath\n",
        "    return _original_ModelCheckpoint(*args, **kwargs)\n",
        "\n",
        "tf.keras.callbacks.ModelCheckpoint = patched_ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEVmUYQnEb__"
      },
      "outputs": [],
      "source": [
        "# 2. Then patch Trainer.__init__\n",
        "from mixnet.trainer import Trainer\n",
        "_original_trainer_init = Trainer.__init__\n",
        "\n",
        "def patched_trainer_init(self, *args, **kwargs):\n",
        "    _original_trainer_init(self, *args, **kwargs)\n",
        "    # Now safely modify the weights_dir\n",
        "    self.weights_dir = os.path.join(self.log_path, self.prefix_log + '_out.weights.h5')\n",
        "\n",
        "Trainer.__init__ = patched_trainer_init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpNJ3_oxLM1b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Monkey patch np.Inf back into NumPy\n",
        "np.Inf = np.inf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gK6iPXtL6ti"
      },
      "source": [
        "# Monkey Patching for Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-Q_P6diAM_B"
      },
      "outputs": [],
      "source": [
        "import keras.callbacks\n",
        "\n",
        "def patched_set_params(self, params):\n",
        "    if \"steps\" not in params:\n",
        "        params[\"steps\"] = 4  # or some default value based on your dataset\n",
        "    self._params = params\n",
        "\n",
        "# Monkey patch\n",
        "keras.callbacks.ProgbarLogger.set_params = patched_set_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMnM9NG8BbJb"
      },
      "outputs": [],
      "source": [
        "# Monkey patch the reset_states method for SparseCategoricalAccuracy\n",
        "import tensorflow as tf\n",
        "\n",
        "# Custom reset_states function\n",
        "def custom_reset_states(self):\n",
        "    self.total.assign(0.0)\n",
        "    self.count.assign(0.0)\n",
        "\n",
        "tf.keras.metrics.SparseCategoricalAccuracy.reset_states = custom_reset_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqRMR6q6nCXc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Patch tf.keras.backend.set_value to avoid crashing on float inputs\n",
        "original_set_value = tf.keras.backend.set_value\n",
        "\n",
        "def safe_set_value(x, value):\n",
        "    try:\n",
        "        # Only call original if x is a variable (has .dtype)\n",
        "        if hasattr(x, \"dtype\"):\n",
        "            value = np.asarray(value, dtype=x.dtype.name)\n",
        "            x.assign(value)\n",
        "        else:\n",
        "            # Skip or log for debugging\n",
        "            print(f\"[Warning] Skipping set_value on float: {x} <- {value}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[Error] set_value patch failed: {e}\")\n",
        "\n",
        "# Apply patch\n",
        "tf.keras.backend.set_value = safe_set_value"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "\n",
        "# # Backup the original function\n",
        "# original_get_memory_info = tf.config.experimental.get_memory_info\n",
        "\n",
        "# # Monkey patch\n",
        "# def dummy_get_memory_info(device):\n",
        "#     print(f\"Monkey patch: Skipping memory info lookup for {device}\")\n",
        "#     return {'current': None, 'peak': None}\n",
        "\n",
        "# tf.config.experimental.get_memory_info = dummy_get_memory_info"
      ],
      "metadata": {
        "id": "monxi-KXmdEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from mixnet.models import BaseModel\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def patched_evaluate(self, X_test, y_test):\n",
        "    model = self.build(print_summary=self.print_summary, load_weights=True)\n",
        "    super(self.__class__, self).compile(model=model)\n",
        "    start = time.time()\n",
        "    evaluation, test_pred = super(self.__class__, self).testing(x=X_test, y=y_test)\n",
        "    end = time.time()\n",
        "\n",
        "    if model.name.startswith('MIN2Net'):\n",
        "        try:\n",
        "            y_pred_decoder, zs, y_pred_clf = test_pred[0], test_pred[1:-1], test_pred[-1]\n",
        "            zs = zs[0] if len(zs) == 1 else np.array(zs)\n",
        "            y_pred_argm = np.argmax(y_pred_clf, axis=1)\n",
        "            Y = {'y_true': y_test, 'y_pred': y_pred_argm, 'y_pred_clf': y_pred_clf, 'latent': zs, 'y_pred_decoder': y_pred_decoder}\n",
        "        except:\n",
        "            y_pred_decoder, y_pred_clf = test_pred[0], test_pred[1]\n",
        "            y_pred_argm = np.argmax(y_pred_clf, axis=1)\n",
        "            Y = {'y_true': y_test, 'y_pred': y_pred_argm, 'y_pred_clf': y_pred_clf, 'y_pred_decoder': y_pred_decoder}\n",
        "\n",
        "    elif model.name.startswith('MixNet'):\n",
        "        y_pred_decoder, zs, y_pred_clf = test_pred[0], test_pred[1:-1], test_pred[-1]\n",
        "        zs = zs[0] if len(zs) == 1 else np.array(zs)\n",
        "        y_pred_argm = np.argmax(y_pred_clf, axis=1)\n",
        "        Y = {'y_true': y_test, 'y_pred': y_pred_argm, 'y_pred_clf': y_pred_clf, 'latent': zs, 'y_pred_decoder': y_pred_decoder}\n",
        "    else:\n",
        "        y_pred_argm = np.argmax(test_pred, axis=1)\n",
        "        Y = {'y_true': y_test, 'y_pred': y_pred_argm, 'y_pred_clf': test_pred}\n",
        "\n",
        "    # Skip GPU memory usage in Colab\n",
        "    mem_usage = None\n",
        "    print(\"Skipping GPU memory usage reporting in Colab.\")\n",
        "\n",
        "    print(\"F1-score is computed based on {}\".format(self.f1_average))\n",
        "    f1 = f1_score(y_test, y_pred_argm, average=self.f1_average)\n",
        "    print(classification_report(y_test, y_pred_argm))\n",
        "\n",
        "    evaluation.update({'f1-score': f1, 'prediction_time': end - start, 'memory_usage': mem_usage})\n",
        "\n",
        "    try:\n",
        "        best_loss_weights = self.best_loss_weights.numpy()\n",
        "    except NotImplementedError:\n",
        "        best_loss_weights = K.eval(self.best_loss_weights)\n",
        "\n",
        "    evaluation.update(dict(zip(\n",
        "        ['w_' + name + '_loss' for name in self.loss_names],\n",
        "        best_loss_weights\n",
        "    )))\n",
        "\n",
        "    return Y, evaluation\n",
        "\n",
        "# Monkey patch it\n",
        "BaseModel.evaluate = patched_evaluate"
      ],
      "metadata": {
        "id": "9IgqB5qdpdkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nkjPRTg4rnm"
      },
      "source": [
        "# Run Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w64etjk7ma1T"
      },
      "outputs": [],
      "source": [
        "# # Training loop\n",
        "# def start_model(subject):\n",
        "#     loader = DataLoader(subject=subject, n_component=args.n_component, num_class=args.num_class, **config.data_params)\n",
        "#     results = []\n",
        "\n",
        "#   # Debug print\n",
        "#     print(config.model_params)\n",
        "\n",
        "#     for fold in range(1, config.data_params.n_folds+1):\n",
        "#         prefix_log = f'S{subject:03d}_fold{fold:02d}'\n",
        "#         model = config.model(prefix_log=prefix_log, **config.model_params)\n",
        "\n",
        "#         X_train, y_train = loader.load_train_set(fold=fold)\n",
        "#         X_val, y_val = loader.load_val_set(fold=fold)\n",
        "#         X_test, y_test = loader.load_test_set(fold=fold)\n",
        "\n",
        "#         print(\"Unique MI classes in training:\", np.unique(y_train))\n",
        "\n",
        "#         model.fit(X_train, y_train, X_val, y_val)\n",
        "#         Y, evaluation = model.evaluate(X_test, y_test)\n",
        "\n",
        "#         csv_file = os.path.join(config.log_path, f'S{subject:03d}_all_results.csv')\n",
        "#         if fold == 1:\n",
        "#             write_log(csv_file, data=evaluation.keys(), mode='w')\n",
        "#         write_log(csv_file, data=evaluation.values(), mode='a')\n",
        "#         results.append(Y)\n",
        "#         tf.keras.backend.clear_session()\n",
        "\n",
        "#     np.save(os.path.join(config.log_path, f'S{subject:03d}_prediction_results.npy'), results)\n",
        "#     print(f'------------------------- S{subject:03d} Done --------------------------')\n",
        "\n",
        "# # Run for given subjects\n",
        "# if args.subjects is None:\n",
        "#     for subject in range(1, config.data_params.n_subjects+1):\n",
        "#         start_model(subject)\n",
        "# elif len(args.subjects) == 2:\n",
        "#     for subject in range(args.subjects[0], args.subjects[1]+1):\n",
        "#         start_model(subject)\n",
        "# else:\n",
        "#     for subject in args.subjects:\n",
        "#         start_model(subject)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model with MLFlow"
      ],
      "metadata": {
        "id": "C6OoxLOw6A4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable Eagar Execution\n",
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)"
      ],
      "metadata": {
        "id": "ZI_ATWC8TI97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow pyngrok --quiet"
      ],
      "metadata": {
        "id": "yK3zRHyg6DTl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7d297c4-e96f-4fc7-ec11-bca17d265c37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m101.7/101.7 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m85.0/85.0 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m233.6/233.6 KB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m114.9/114.9 KB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m147.8/147.8 KB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m44.4/44.4 KB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m65.5/65.5 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m65.8/65.8 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m700.2/700.2 KB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m207.6/207.6 KB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m203.4/203.4 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m606.0/606.0 KB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m194.9/194.9 KB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import subprocess\n",
        "from pyngrok import ngrok, conf\n",
        "import getpass\n",
        "\n",
        "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\"\n",
        "subprocess.Popen([\"mlflow\", \"ui\", \"--backend-store-uri\", MLFLOW_TRACKING_URI])\n",
        "\n",
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "mlflow.set_experiment(\"Mixnet-experiment\")\n",
        "\n",
        "# token is 2x7FsnDPDW0XzUJVq1hdIwhxeZs_3vgQSmYx7Yg45uNtK8bZd\n",
        "print(\"Please add token\")\n",
        "conf.get_default().auth_token = getpass.getpass()\n",
        "port=5000\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f' * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{port}\\\"')"
      ],
      "metadata": {
        "id": "-etO9_mnJ6qB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2709c1b-0463-4379-887c-f55ee4269b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please add token\n",
            "\n",
            " * ngrok tunnel \"https://eec7-104-196-24-207.ngrok-free.app\" -> \"http://127.0.0.1:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "import mlflow.keras\n",
        "\n",
        "def start_model(subject):\n",
        "    loader = DataLoader(subject=subject, n_component=args.n_component, num_class=args.num_class, **config.data_params)\n",
        "    results = []\n",
        "\n",
        "    # print(config.model_params)\n",
        "\n",
        "    for fold in range(1, config.data_params.n_folds + 1):\n",
        "        prefix_log = f'S{subject:03d}_fold{fold:02d}'\n",
        "        model = config.model(prefix_log=prefix_log, **config.model_params)\n",
        "\n",
        "        X_train, y_train = loader.load_train_set(fold=fold)\n",
        "        X_val, y_val = loader.load_val_set(fold=fold)\n",
        "        X_test, y_test = loader.load_test_set(fold=fold)\n",
        "\n",
        "        print(\"Unique MI classes in training:\", np.unique(y_train))\n",
        "\n",
        "        with mlflow.start_run(run_name=prefix_log):  # Start MLflow run for this fold\n",
        "            # Log params\n",
        "            mlflow.log_param(\"subject\", subject)\n",
        "            mlflow.log_param(\"fold\", fold)\n",
        "            mlflow.log_param(\"num_classes\", args.num_class)\n",
        "            mlflow.log_param(\"n_components\", args.n_component)\n",
        "            # Log any model params if you want:\n",
        "            for k, v in config.model_params.items():\n",
        "                mlflow.log_param(k, v)\n",
        "\n",
        "            model.fit(X_train, y_train, X_val, y_val)\n",
        "            Y, evaluation = model.evaluate(X_test, y_test)\n",
        "\n",
        "            # Log metrics\n",
        "            for metric_name, metric_value in evaluation.items():\n",
        "                if metric_value is not None:\n",
        "                    mlflow.log_metric(metric_name, float(metric_value))\n",
        "\n",
        "            # Log model artifact\n",
        "            mlflow.keras.log_model(model, artifact_path=\"model\")\n",
        "\n",
        "            csv_file = os.path.join(config.log_path, f'S{subject:03d}_all_results.csv')\n",
        "            if fold == 1:\n",
        "                write_log(csv_file, data=evaluation.keys(), mode='w')\n",
        "            write_log(csv_file, data=evaluation.values(), mode='a')\n",
        "            results.append(Y)\n",
        "\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    np.save(os.path.join(config.log_path, f'S{subject:03d}_prediction_results.npy'), results)\n",
        "    print(f'------------------------- S{subject:03d} Done --------------------------')\n",
        "\n",
        "\n",
        "# Run for given subjects\n",
        "if args.subjects is None:\n",
        "    for subject in range(1, config.data_params.n_subjects+1):\n",
        "        start_model(subject)\n",
        "elif len(args.subjects) == 2:\n",
        "    for subject in range(args.subjects[0], args.subjects[1]+1):\n",
        "        start_model(subject)\n",
        "else:\n",
        "    for subject in args.subjects:\n",
        "        start_model(subject)"
      ],
      "metadata": {
        "id": "HAgMita16J_H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9babf1c-9224-4c43-9f47-7ef9aac554f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The datset used is:  datasets/BCIC2a/spectral_spatial_signals/2_class/2_csp_components/subject_dependent\n",
            "change data_format to 'NTCD', new dimention is (115, 1, 400, 18)\n",
            "change data_format to 'NTCD', new dimention is (29, 1, 400, 18)\n",
            "change data_format to 'NTCD', new dimention is (144, 1, 400, 18)\n",
            "Unique MI classes in training: [0. 1.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"encoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"encoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " en_input (\u001b[38;5;33mInputLayer\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " en_conv1 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m18\u001b[0m)             \u001b[38;5;34m20,754\u001b[0m \n",
              "\n",
              " en_bn1 (\u001b[38;5;33mBatchNormalization\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m18\u001b[0m)                 \u001b[38;5;34m72\u001b[0m \n",
              "\n",
              " en_avg1 (\u001b[38;5;33mAveragePooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m18\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " en_conv2 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m9\u001b[0m)               \u001b[38;5;34m5,193\u001b[0m \n",
              "\n",
              " en_bn2 (\u001b[38;5;33mBatchNormalization\u001b[0m)      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m9\u001b[0m)                  \u001b[38;5;34m36\u001b[0m \n",
              "\n",
              " en_avg2 (\u001b[38;5;33mAveragePooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m9\u001b[0m)                    \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " en_flat (\u001b[38;5;33mFlatten\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m225\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " z (\u001b[38;5;33mDense\u001b[0m)                        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                      \u001b[38;5;34m4,068\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " en_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " en_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">20,754</span> \n",
              "\n",
              " en_bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> \n",
              "\n",
              " en_avg1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " en_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">5,193</span> \n",
              "\n",
              " en_bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> \n",
              "\n",
              " en_avg2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " en_flat (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " z (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,068</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,123\u001b[0m (117.67 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,123</span> (117.67 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,069\u001b[0m (117.46 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,069</span> (117.46 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m54\u001b[0m (216.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54</span> (216.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"decoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"decoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " de_input (\u001b[38;5;33mInputLayer\u001b[0m)            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " de_dense (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m225\u001b[0m)                     \u001b[38;5;34m4,275\u001b[0m \n",
              "\n",
              " de_reshape (\u001b[38;5;33mReshape\u001b[0m)             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m9\u001b[0m)                    \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " de_deconv1 (\u001b[38;5;33mConv2DTranspose\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m9\u001b[0m)               \u001b[38;5;34m5,193\u001b[0m \n",
              "\n",
              " de_deconv2 (\u001b[38;5;33mConv2DTranspose\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m18\u001b[0m)              \u001b[38;5;34m5,202\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " de_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " de_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">225</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,275</span> \n",
              "\n",
              " de_reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " de_deconv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">5,193</span> \n",
              "\n",
              " de_deconv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">5,202</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,670\u001b[0m (57.30 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,670</span> (57.30 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,670\u001b[0m (57.30 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,670</span> (57.30 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"MixNet\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MixNet\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " en_input             (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m400\u001b[0m,              \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)         \u001b[38;5;34m18\u001b[0m)                                              \n",
              "\n",
              " encoder              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             \u001b[38;5;34m30,123\u001b[0m  en_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    \n",
              " (\u001b[38;5;33mFunctional\u001b[0m)                                                          \n",
              "\n",
              " decoder              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m400\u001b[0m,         \u001b[38;5;34m14,670\u001b[0m  encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
              " (\u001b[38;5;33mFunctional\u001b[0m)         \u001b[38;5;34m18\u001b[0m)                                              \n",
              "\n",
              " classifier (\u001b[38;5;33mDense\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                  \u001b[38;5;34m38\u001b[0m  encoder[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " en_input             (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>,              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                                              \n",
              "\n",
              " encoder              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">30,123</span>  en_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                                                          \n",
              "\n",
              " decoder              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>,         <span style=\"color: #00af00; text-decoration-color: #00af00\">14,670</span>  encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)                                              \n",
              "\n",
              " classifier (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>  encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,831\u001b[0m (175.12 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,831</span> (175.12 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,777\u001b[0m (174.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,777</span> (174.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m54\u001b[0m (216.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54</span> (216.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This iteration is taking into account of class weight:  {np.float64(0.0): np.float64(0.9913793103448276), np.float64(1.0): np.float64(1.0087719298245614)}\n",
            "This iteration is taking into account of batch size:  32\n",
            "... build adaptive policy: <class 'mixnet.gradients.HistoricalTangentSlope'>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unknown variable: <Variable path=en_conv1/kernel, shape=(1, 64, 18, 18), dtype=float32, value=[[[[ 0.0508449   0.01224373 -0.02708537 ... -0.0065275  -0.00645919\n     0.02701908]\n   [ 0.02400442  0.03665604 -0.03778405 ... -0.04621503 -0.0198004\n     0.0507599 ]\n   [ 0.0393696  -0.03699367 -0.03482965 ... -0.0124479   0.01165529\n    -0.00614947]\n   ...\n   [ 0.02315049 -0.00324251  0.02943146 ... -0.03744549 -0.02402198\n     0.03831054]\n   [-0.04843787  0.05054585 -0.00407214 ...  0.02254617 -0.00080433\n     0.04724251]\n   [-0.03053211 -0.01825906  0.01219448 ... -0.03765123  0.00935333\n     0.01390088]]\n\n  [[ 0.00794766 -0.02693652 -0.03703897 ...  0.04530798  0.0130543\n    -0.04370594]\n   [-0.00602334  0.0179512   0.01645517 ... -0.04762358 -0.05060536\n    -0.01525725]\n   [ 0.0469792   0.0217272   0.0200121  ... -0.04291404 -0.03420717\n     0.0470174 ]\n   ...\n   [-0.04724599 -0.03905784  0.00051304 ... -0.01085679  0.01958118\n    -0.01207232]\n   [-0.01033536  0.02066363  0.0291982  ... -0.00783505 -0.03338566\n     0.04413778]\n   [-0.03055911 -0.02955335 -0.01207662 ...  0.03939489 -0.01680417\n     0.0466026 ]]\n\n  [[ 0.04671282  0.03808888 -0.03628451 ... -0.00068956  0.0372581\n    -0.03027379]\n   [-0.03863493  0.02777335  0.02543499 ... -0.00209784 -0.02114532\n    -0.00657124]\n   [ 0.00180636 -0.01577944  0.01383658 ...  0.04377129  0.03733554\n    -0.04794708]\n   ...\n   [-0.00793059  0.01348671  0.0200221  ... -0.04440999 -0.02433409\n     0.03790319]\n   [-0.02740544  0.03862188  0.0259274  ... -0.03927627 -0.01961484\n    -0.03831067]\n   [-0.03190798  0.05090285  0.01783284 ...  0.01381213 -0.0399237\n     0.02627155]]\n\n  ...\n\n  [[-0.02217061  0.03585012  0.00555414 ... -0.03911248  0.03006228\n     0.02888627]\n   [-0.05076019  0.04708883  0.00299918 ... -0.01992091 -0.04445828\n    -0.01550411]\n   [-0.02653556  0.01492438 -0.01829393 ... -0.02829126 -0.03601176\n     0.04860945]\n   ...\n   [ 0.02952325  0.00089283 -0.03110068 ... -0.0164423   0.04016683\n    -0.01974078]\n   [-0.00280929 -0.01798132 -0.03703199 ... -0.01221657 -0.00432508\n     0.03442913]\n   [-0.02201438 -0.01472005 -0.01894021 ... -0.01449574 -0.02969145\n    -0.02792402]]\n\n  [[-0.02712506 -0.00804942 -0.03272302 ... -0.04972139 -0.00699027\n     0.04649155]\n   [ 0.02189021 -0.02595845 -0.04620864 ... -0.04100599  0.01187574\n    -0.00659145]\n   [ 0.04275045  0.02213669 -0.03839456 ...  0.01828915  0.01017344\n     0.04776093]\n   ...\n   [-0.04625529  0.02837855  0.00656782 ... -0.02770467  0.03764269\n    -0.02092911]\n   [-0.02211149 -0.02620154 -0.04013483 ...  0.04333354  0.02887343\n     0.03197188]\n   [-0.0252087   0.03992061  0.03855388 ...  0.00291263 -0.0148203\n     0.05040277]]\n\n  [[ 0.00402222  0.03496914  0.02164996 ...  0.04500942  0.04050948\n    -0.03089331]\n   [-0.05044119  0.01944175 -0.00703082 ...  0.04001617 -0.04097084\n     0.02691194]\n   [-0.04652219 -0.00916048  0.01027293 ...  0.02856214  0.01490985\n     0.03607652]\n   ...\n   [-0.02811467  0.04280108  0.00806581 ... -0.01133986 -0.00472447\n    -0.02051417]\n   [-0.03921156  0.04626244 -0.0253796  ...  0.00879325  0.02797027\n    -0.04500621]\n   [-0.01919571  0.01874799 -0.03287383 ...  0.03570995 -0.01457446\n     0.03590184]]]]>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-121761d4ff0c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubjects\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msubject\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_subjects\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mstart_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubjects\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msubject\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubjects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubjects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-121761d4ff0c>\u001b[0m in \u001b[0;36mstart_model\u001b[0;34m(subject)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mixnet/models/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprint_summary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mixnet/trainer.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self, x, y, validation_data)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                 \u001b[0mtmp_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m                 \u001b[0mtrain_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/mixnet/models/MixNet.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, x, y, loss_weights)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_logis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mloss_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_loss'\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    422\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables_are_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36m_check_variables_are_known\u001b[0;34m(self, variables)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable_variables_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    330\u001b[0m                     \u001b[0;34mf\"Unknown variable: {v}. This optimizer can only \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0;34m\"be called for the variables it was originally built with. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown variable: <Variable path=en_conv1/kernel, shape=(1, 64, 18, 18), dtype=float32, value=[[[[ 0.0508449   0.01224373 -0.02708537 ... -0.0065275  -0.00645919\n     0.02701908]\n   [ 0.02400442  0.03665604 -0.03778405 ... -0.04621503 -0.0198004\n     0.0507599 ]\n   [ 0.0393696  -0.03699367 -0.03482965 ... -0.0124479   0.01165529\n    -0.00614947]\n   ...\n   [ 0.02315049 -0.00324251  0.02943146 ... -0.03744549 -0.02402198\n     0.03831054]\n   [-0.04843787  0.05054585 -0.00407214 ...  0.02254617 -0.00080433\n     0.04724251]\n   [-0.03053211 -0.01825906  0.01219448 ... -0.03765123  0.00935333\n     0.01390088]]\n\n  [[ 0.00794766 -0.02693652 -0.03703897 ...  0.04530798  0.0130543\n    -0.04370594]\n   [-0.00602334  0.0179512   0.01645517 ... -0.04762358 -0.05060536\n    -0.01525725]\n   [ 0.0469792   0.0217272   0.0200121  ... -0.04291404 -0.03420717\n     0.0470174 ]\n   ...\n   [-0.04724599 -0.03905784  0.00051304 ... -0.01085679  0.01958118\n    -0.01207232]\n   [-0.01033536  0.02066363  0.0291982  ... -0.00783505 -0.03338566\n     0.04413778]\n   [-0.03055911 -0.02955335 -0.01207662 ...  0.03939489 -0.01680417\n     0.0466026 ]]\n\n  [[ 0.04671282  0.03808888 -0.03628451 ... -0.00068956  0.0372581\n    -0.03027379]\n   [-0.03863493  0.02777335  0.02543499 ... -0.00209784 -0.02114532\n    -0.00657124]\n   [ 0.00180636 -0.01577944  0.01383658 ...  0.04377129  0.03733554\n    -0.04794708]\n   ...\n   [-0.00793059  0.01348671  0.0200221  ... -0.04440999 -0.02433409\n     0.03790319]\n   [-0.02740544  0.03862188  0.0259274  ... -0.03927627 -0.01961484\n    -0.03831067]\n   [-0.03190798  0.05090285  0.01783284 ...  0.01381213 -0.0399237\n     0.02627155]]\n\n  ...\n\n  [[-0.02217061  0.03585012  0.00555414 ... -0.03911248  0.03006228\n     0.02888627]\n   [-0.05076019  0.04708883  0.00299918 ... -0.01992091 -0.04445828\n    -0.01550411]\n   [-0.02653556  0.01492438 -0.01829393 ... -0.02829126 -0.03601176\n     0.04860945]\n   ...\n   [ 0.02952325  0.00089283 -0.03110068 ... -0.0164423   0.04016683\n    -0.01974078]\n   [-0.00280929 -0.01798132 -0.03703199 ... -0.01221657 -0.00432508\n     0.03442913]\n   [-0.02201438 -0.01472005 -0.01894021 ... -0.01449574 -0.02969145\n    -0.02792402]]\n\n  [[-0.02712506 -0.00804942 -0.03272302 ... -0.04972139 -0.00699027\n     0.04649155]\n   [ 0.02189021 -0.02595845 -0.04620864 ... -0.04100599  0.01187574\n    -0.00659145]\n   [ 0.04275045  0.02213669 -0.03839456 ...  0.01828915  0.01017344\n     0.04776093]\n   ...\n   [-0.04625529  0.02837855  0.00656782 ... -0.02770467  0.03764269\n    -0.02092911]\n   [-0.02211149 -0.02620154 -0.04013483 ...  0.04333354  0.02887343\n     0.03197188]\n   [-0.0252087   0.03992061  0.03855388 ...  0.00291263 -0.0148203\n     0.05040277]]\n\n  [[ 0.00402222  0.03496914  0.02164996 ...  0.04500942  0.04050948\n    -0.03089331]\n   [-0.05044119  0.01944175 -0.00703082 ...  0.04001617 -0.04097084\n     0.02691194]\n   [-0.04652219 -0.00916048  0.01027293 ...  0.02856214  0.01490985\n     0.03607652]\n   ...\n   [-0.02811467  0.04280108  0.00806581 ... -0.01133986 -0.00472447\n    -0.02051417]\n   [-0.03921156  0.04626244 -0.0253796  ...  0.00879325  0.02797027\n    -0.04500621]\n   [-0.01919571  0.01874799 -0.03287383 ...  0.03570995 -0.01457446\n     0.03590184]]]]>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}